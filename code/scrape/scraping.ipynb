{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from getpass import getuser\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the current user's name\n",
    "user = getuser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the notebook to load functions\n",
    "%run scraping_functions.ipynb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FIFA World Cup 1984 page does not exist. Skipping...\n",
      "FIFA World Cup 1985 page does not exist. Skipping...\n",
      "Scraping FIFA World Cup 1986 data...\n",
      "FIFA World Cup 1987 page does not exist. Skipping...\n",
      "FIFA World Cup 1988 page does not exist. Skipping...\n",
      "FIFA World Cup 1989 page does not exist. Skipping...\n",
      "Scraping FIFA World Cup 1990 data...\n",
      "Scraping FIFA World Cup 1991 data...\n",
      "FIFA World Cup 1992 page does not exist. Skipping...\n",
      "FIFA World Cup 1993 page does not exist. Skipping...\n",
      "Scraping FIFA World Cup 1994 data...\n",
      "Scraping FIFA World Cup 1995 data...\n",
      "FIFA World Cup 1996 page does not exist. Skipping...\n",
      "FIFA World Cup 1997 page does not exist. Skipping...\n",
      "Scraping FIFA World Cup 1998 data...\n",
      "FIFA World Cup 1999 page does not exist. Skipping...\n",
      "FIFA World Cup 2000 page does not exist. Skipping...\n",
      "FIFA World Cup 2001 page does not exist. Skipping...\n",
      "Scraping FIFA World Cup 2002 data...\n",
      "FIFA World Cup 2003 page does not exist. Skipping...\n",
      "FIFA World Cup 2004 page does not exist. Skipping...\n",
      "FIFA World Cup 2005 page does not exist. Skipping...\n",
      "Scraping FIFA World Cup 2006 data...\n",
      "Scraping FIFA World Cup 2007 data...\n",
      "FIFA World Cup 2008 page does not exist. Skipping...\n",
      "FIFA World Cup 2009 page does not exist. Skipping...\n",
      "Scraping FIFA World Cup 2010 data...\n",
      "Scraping FIFA World Cup 2011 data...\n",
      "FIFA World Cup 2012 page does not exist. Skipping...\n",
      "FIFA World Cup 2013 page does not exist. Skipping...\n",
      "Scraping FIFA World Cup 2014 data...\n",
      "Scraping FIFA World Cup 2015 data...\n",
      "Scraping FIFA World Cup 2016 data...\n",
      "Scraping FIFA World Cup 2017 data...\n",
      "Scraping FIFA World Cup 2018 data...\n",
      "Scraping FIFA World Cup 2019 data...\n",
      "FIFA World Cup 2020 page does not exist. Skipping...\n",
      "FIFA World Cup 2021 page does not exist. Skipping...\n",
      "Scraping FIFA World Cup 2022 data...\n",
      "Scraping FIFA World Cup 2023 data...\n",
      "FIFA World Cup 2024 page does not exist. Skipping...\n",
      "Data saved to C:\\Users\\aldi\\Documents\\GitHub\\tiebreak_wc\\data\\in\\wc_goals.xlsx\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Define the range boundaries\n",
    "start_year = 1984\n",
    "end_year = 2024\n",
    "\n",
    "# Initialize a list to store data for all editions\n",
    "all_matches_data = []\n",
    "\n",
    "# Loop through each year in the range and check if the page exists\n",
    "for year in range(start_year, end_year + 1):  # Increment by 1 to check each year\n",
    "    url = f'https://en.wikipedia.org/wiki/{year}_FIFA_World_Cup'\n",
    "    response = requests.head(url)\n",
    "\n",
    "    # Check if the page exists (status code 200)\n",
    "    if response.status_code == 200:\n",
    "        print(f\"Scraping FIFA World Cup {year} data...\")\n",
    "        year_data = scraper(url)  # Assuming `scraper` function is defined in scraping_functions.ipynb\n",
    "        all_matches_data.extend(year_data)\n",
    "    else:\n",
    "        print(f\"FIFA World Cup {year} page does not exist. Skipping...\")\n",
    "\n",
    "# Convert the collected data to a DataFrame\n",
    "all_matches_df = pd.DataFrame(all_matches_data)\n",
    "\n",
    "# Clean the data\n",
    "all_matches_df_cleaned = clean_data(all_matches_df)  # Assuming `clean_data` function is defined in scraping_functions.ipynb\n",
    "\n",
    "# Define the file path for saving the cleaned data\n",
    "file_path = rf'C:\\Users\\{user}\\Documents\\GitHub\\tiebreak_wc\\data\\in\\wc_goals.xlsx'\n",
    "\n",
    "# Export the cleaned data to an Excel file\n",
    "all_matches_df_cleaned.to_excel(file_path, index=False)\n",
    "print(f\"Data saved to {file_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping Euro 1984 data...\n",
      "FIFA Euro 1985 page does not exist. Skipping...\n",
      "FIFA Euro 1986 page does not exist. Skipping...\n",
      "FIFA Euro 1987 page does not exist. Skipping...\n",
      "Scraping Euro 1988 data...\n",
      "FIFA Euro 1989 page does not exist. Skipping...\n",
      "FIFA Euro 1990 page does not exist. Skipping...\n",
      "FIFA Euro 1991 page does not exist. Skipping...\n",
      "Scraping Euro 1992 data...\n",
      "FIFA Euro 1993 page does not exist. Skipping...\n",
      "FIFA Euro 1994 page does not exist. Skipping...\n",
      "FIFA Euro 1995 page does not exist. Skipping...\n",
      "Scraping Euro 1996 data...\n",
      "FIFA Euro 1997 page does not exist. Skipping...\n",
      "FIFA Euro 1998 page does not exist. Skipping...\n",
      "FIFA Euro 1999 page does not exist. Skipping...\n",
      "Scraping Euro 2000 data...\n",
      "FIFA Euro 2001 page does not exist. Skipping...\n",
      "FIFA Euro 2002 page does not exist. Skipping...\n",
      "FIFA Euro 2003 page does not exist. Skipping...\n",
      "Scraping Euro 2004 data...\n",
      "FIFA Euro 2005 page does not exist. Skipping...\n",
      "FIFA Euro 2006 page does not exist. Skipping...\n",
      "FIFA Euro 2007 page does not exist. Skipping...\n",
      "Scraping Euro 2008 data...\n",
      "FIFA Euro 2009 page does not exist. Skipping...\n",
      "FIFA Euro 2010 page does not exist. Skipping...\n",
      "FIFA Euro 2011 page does not exist. Skipping...\n",
      "Scraping Euro 2012 data...\n",
      "Scraping Euro 2013 data...\n",
      "FIFA Euro 2014 page does not exist. Skipping...\n",
      "FIFA Euro 2015 page does not exist. Skipping...\n",
      "Scraping Euro 2016 data...\n",
      "FIFA Euro 2017 page does not exist. Skipping...\n",
      "FIFA Euro 2018 page does not exist. Skipping...\n",
      "FIFA Euro 2019 page does not exist. Skipping...\n",
      "Scraping Euro 2020 data...\n",
      "Scraping Euro 2021 data...\n",
      "Scraping Euro 2022 data...\n",
      "FIFA Euro 2023 page does not exist. Skipping...\n",
      "Scraping Euro 2024 data...\n",
      "Data saved to C:\\Users\\aldi\\Documents\\GitHub\\tiebreak_wc\\data\\in\\eu_goals.xlsx\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Define the range boundaries\n",
    "start_year = 1984\n",
    "end_year = 2024\n",
    "\n",
    "# Initialize a list to store data for all editions\n",
    "all_matches_data = []\n",
    "\n",
    "# Loop through each year in the range and check if the page exists\n",
    "for year in range(start_year, end_year + 1):  # Increment by 1 to check each year\n",
    "    url = f'https://en.wikipedia.org/wiki/UEFA_Euro_{year}'\n",
    "    response = requests.head(url)\n",
    "\n",
    "    # Check if the page exists (status code 200)\n",
    "    if response.status_code == 200:\n",
    "        print(f\"Scraping Euro {year} data...\")\n",
    "        year_data = scraper(url)  # Assuming `scraper` function is defined in scraping_functions.ipynb\n",
    "        all_matches_data.extend(year_data)\n",
    "    else:\n",
    "        print(f\"FIFA Euro {year} page does not exist. Skipping...\")\n",
    "\n",
    "# Convert the collected data to a DataFrame\n",
    "all_matches_df = pd.DataFrame(all_matches_data)\n",
    "\n",
    "# Clean the data\n",
    "all_matches_df_cleaned = clean_data(all_matches_df)  # Assuming `clean_data` function is defined in scraping_functions.ipynb\n",
    "\n",
    "# Define the file path for saving the cleaned data\n",
    "file_path = rf'C:\\Users\\{user}\\Documents\\GitHub\\tiebreak_wc\\data\\in\\eu_goals.xlsx'\n",
    "\n",
    "# Export the cleaned data to an Excel file\n",
    "all_matches_df_cleaned.to_excel(file_path, index=False)\n",
    "print(f\"Data saved to {file_path}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
