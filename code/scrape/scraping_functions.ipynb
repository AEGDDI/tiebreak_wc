{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def scraper(start_year, end_year, url_template):\n",
    "    # Initialize a list to store data for all editions in the range\n",
    "    all_matches_data = []\n",
    "\n",
    "    # Loop through each year in the specified range\n",
    "    for year in range(start_year, end_year + 1):\n",
    "        # Construct the URL for each year using the provided template\n",
    "        url = url_template.format(year=year)\n",
    "        print(f\"Attempting to scrape {url}\")\n",
    "        \n",
    "        # Send a request to fetch the HTML content of the page\n",
    "        try:\n",
    "            response = requests.get(url, allow_redirects=True, timeout=10)\n",
    "        except requests.RequestException as e:\n",
    "            print(f\"Network error while fetching {url}: {e}\")\n",
    "            continue  # Skip to the next year if there's a network error\n",
    "\n",
    "        # Check if the response status code is OK\n",
    "        if response.status_code == 404:\n",
    "            print(f\"Page not found: {url} (status code 404)\")\n",
    "            continue\n",
    "        elif response.status_code != 200:\n",
    "            print(f\"Failed to retrieve {url}, status code: {response.status_code}\")\n",
    "            continue\n",
    "        \n",
    "        # Detect if there was a redirect, and print the final URL\n",
    "        if response.history:\n",
    "            print(f\"Redirected for {url} - Final URL: {response.url}\")\n",
    "\n",
    "        # Parse the page content\n",
    "        soup = BeautifulSoup(response.content, 'html.parser')\n",
    "        \n",
    "        # Find all divs with the class 'footballbox'\n",
    "        footballbox_divs = soup.find_all('div', {'class': 'footballbox'})\n",
    "        if not footballbox_divs:\n",
    "            print(f\"No 'footballbox' divs found on {url}. Page structure may have changed.\")\n",
    "            continue\n",
    "\n",
    "        # Initialize a list to store expanded match data with individual goals per row\n",
    "        expanded_matches_data = []\n",
    "\n",
    "        # Initialize a variable to store the current stage (from h3 tags)\n",
    "        current_stage = None\n",
    "\n",
    "        # Iterate through each 'footballbox' div\n",
    "        for idx, box in enumerate(footballbox_divs, start=1):\n",
    "            print(f\"Processing match box {idx} on page for {year}\")\n",
    "\n",
    "            # Find the closest preceding h3 tag to track the stage\n",
    "            previous_h3 = box.find_previous('h3')\n",
    "            if previous_h3:\n",
    "                current_stage = previous_h3.get_text(strip=True)\n",
    "            else:\n",
    "                print(f\"No stage found for match box {idx} on {url}\")\n",
    "            \n",
    "            # Initialize a dictionary to store match information\n",
    "            match_info = {\n",
    "                'year': year,\n",
    "                'stage': current_stage,\n",
    "                'score': None,  # Default value for score\n",
    "            }\n",
    "\n",
    "            # Step 1: Extracting date and time from div class 'fleft'\n",
    "            fleft = box.find('div', {'class': 'fleft'})\n",
    "            if fleft:\n",
    "                match_info['date'] = fleft.find('div', {'class': 'fdate'}).get_text(strip=True) if fleft.find('div', {'class': 'fdate'}) else None\n",
    "                match_info['time'] = fleft.find('div', {'class': 'ftime'}).get_text(strip=True) if fleft.find('div', {'class': 'ftime'}) else None\n",
    "            else:\n",
    "                print(f\"Warning: No 'fleft' div found for match box {idx} on {url}\")\n",
    "\n",
    "            # Step 2: Extracting home team, away team, and score from table class 'fevent'\n",
    "            fevent_table = box.find('table', {'class': 'fevent'})\n",
    "            if fevent_table:\n",
    "                match_info['home_team'] = fevent_table.find('th', {'class': 'fhome'}).get_text(strip=True) if fevent_table.find('th', {'class': 'fhome'}) else None\n",
    "                match_info['away_team'] = fevent_table.find('th', {'class': 'faway'}).get_text(strip=True) if fevent_table.find('th', {'class': 'faway'}) else None\n",
    "                match_info['score'] = fevent_table.find('th', {'class': 'fscore'}).get_text(strip=True) if fevent_table.find('th', {'class': 'fscore'}) else match_info['score']\n",
    "                \n",
    "                if not match_info['home_team'] or not match_info['away_team']:\n",
    "                    print(f\"Warning: Missing team information for match box {idx} on {url}\")\n",
    "                \n",
    "                if match_info['score'] is None:\n",
    "                    print(f\"Warning: No score found for match box {idx} on {url}\")\n",
    "            else:\n",
    "                print(f\"Warning: No 'fevent' table found for match box {idx} on {url}\")\n",
    "\n",
    "            # Step 3: Extracting stadium and referee information from div class 'fright'\n",
    "            fright = box.find('div', {'class': 'fright'})\n",
    "            if fright:\n",
    "                location_div = fright.find('div', {'itemprop': 'location'})\n",
    "                if location_div:\n",
    "                    match_info['stadium_name'] = location_div.find('a').get_text(strip=True) if location_div.find('a') else None\n",
    "                    match_info['stadium_city'] = location_div.find_all('a')[1].get_text(strip=True) if len(location_div.find_all('a')) > 1 else None\n",
    "                else:\n",
    "                    print(f\"Warning: No stadium location found for match box {idx} on {url}\")\n",
    "\n",
    "                stadium_attendance = fright.find_all('div')[1].get_text(strip=True) if len(fright.find_all('div')) > 1 else None\n",
    "                match_info['stadium_attendance'] = stadium_attendance\n",
    "\n",
    "                referee_div = fright.find_all('div')[2] if len(fright.find_all('div')) > 2 else None\n",
    "                if referee_div:\n",
    "                    match_info['referee_name'] = referee_div.find('a').get_text(strip=True) if referee_div.find('a') else None\n",
    "                    match_info['referee_nationality'] = referee_div.find_all('a')[1].get_text(strip=True) if len(referee_div.find_all('a')) > 1 else None\n",
    "                else:\n",
    "                    print(f\"Warning: No referee information found for match box {idx} on {url}\")\n",
    "            else:\n",
    "                print(f\"Warning: No 'fright' div found for match box {idx} on {url}\")\n",
    "\n",
    "            # Step 4: Extract individual goals for home and away teams\n",
    "            fgoals_rows = fevent_table.find_all('tr', {'class': 'fgoals'}) if fevent_table else []\n",
    "            \n",
    "            for goal_row in fgoals_rows:\n",
    "                # Handle home team goals\n",
    "                home_goals = goal_row.find_all('td', {'class': 'fhgoal'})\n",
    "                for home_goal in home_goals:\n",
    "                    plainlist = home_goal.find('div', {'class': 'plainlist'})\n",
    "                    if plainlist:\n",
    "                        scorers = plainlist.find_all('li')\n",
    "                        for scorer in scorers:\n",
    "                            scorer_name = scorer.find('a').get_text(strip=True) if scorer.find('a') else None\n",
    "                            if scorer_name:\n",
    "                                goal_minutes = scorer.find_all('span', {'class': 'fb-goal'})\n",
    "                                for minute in goal_minutes:\n",
    "                                    match_copy = match_info.copy()\n",
    "                                    match_copy['scorer_name'] = scorer_name\n",
    "                                    match_copy['scorer_nationality'] = match_info.get('home_team')\n",
    "                                    match_copy['goal_minute'] = minute.get_text(strip=True)\n",
    "                                    expanded_matches_data.append(match_copy)\n",
    "\n",
    "                # Handle away team goals\n",
    "                away_goals = goal_row.find_all('td', {'class': 'fagoal'})\n",
    "                for away_goal in away_goals:\n",
    "                    plainlist = away_goal.find('div', {'class': 'plainlist'})\n",
    "                    if plainlist:\n",
    "                        scorers = plainlist.find_all('li')\n",
    "                        for scorer in scorers:\n",
    "                            scorer_name = scorer.find('a').get_text(strip=True) if scorer.find('a') else None\n",
    "                            if scorer_name:\n",
    "                                goal_minutes = scorer.find_all('span', {'class': 'fb-goal'})\n",
    "                                for minute in goal_minutes:\n",
    "                                    match_copy = match_info.copy()\n",
    "                                    match_copy['scorer_name'] = scorer_name\n",
    "                                    match_copy['scorer_nationality'] = match_info.get('away_team')\n",
    "                                    match_copy['goal_minute'] = minute.get_text(strip=True)\n",
    "                                    expanded_matches_data.append(match_copy)\n",
    "\n",
    "        # Add all match data for the current year\n",
    "        all_matches_data.extend(expanded_matches_data)\n",
    "\n",
    "    if not all_matches_data:\n",
    "        print(f\"No match data found in the specified range {start_year} - {end_year}.\")\n",
    "    \n",
    "    # Return the list of all match data collected in the range\n",
    "    return all_matches_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_data(df):\n",
    "    # Check for extra time in the score and remove it\n",
    "    df['extra_time'] = df['score'].apply(lambda x: 1 if '(a.e.t.)' in str(x) else 0)\n",
    "    df['score'] = df['score'].str.replace(r'\\(a.e.t.\\)', '', regex=True).str.strip()\n",
    "    df['score'] = df['score'].str.replace(r'[^\\d–]', '', regex=True).str.strip()\n",
    "    df['score'] = df['score'].fillna('0–0')\n",
    "\n",
    "    # Splitting the score into goals_home and goals_away\n",
    "    df[['goals_home', 'goals_away']] = df['score'].str.split('–', expand=True)\n",
    "    df['goals_home'] = pd.to_numeric(df['goals_home'], errors='coerce').fillna(0).astype(int)\n",
    "    df['goals_away'] = pd.to_numeric(df['goals_away'], errors='coerce').fillna(0).astype(int)\n",
    "\n",
    "    # Duplicate rows for cases where goal_minute contains a comma\n",
    "    df = df.assign(goal_minute=df['goal_minute'].str.split(',')).explode('goal_minute')\n",
    "\n",
    "    # Create own_goal and penalty flags\n",
    "    df['own_goal'] = df['goal_minute'].apply(lambda x: 1 if '(o.g.)' in str(x) else 0)\n",
    "    df['penalty'] = df['goal_minute'].apply(lambda x: 1 if '(pen.)' in str(x) else 0)\n",
    "\n",
    "    # Clean goal_minute by removing '(o.g.)', '(pen.)', and any apostrophes\n",
    "    df['goal_minute'] = df['goal_minute'].str.replace(r'\\(o.g.\\)', '', regex=True)\n",
    "    df['goal_minute'] = df['goal_minute'].str.replace(r'\\(pen.\\)', '', regex=True)\n",
    "    df['goal_minute'] = df['goal_minute'].str.replace(\"'\", \"\").str.strip()\n",
    "\n",
    "    # Process goal_minute to handle extra time\n",
    "    df['goal_minute_et'] = df['goal_minute'].apply(lambda x: int(x.split('+')[1]) if '+' in str(x) else 0)\n",
    "    df['goal_minute'] = df['goal_minute'].apply(lambda x: int(x.split('+')[0]) if '+' in str(x) else int(x))\n",
    "\n",
    "    # Create goal_et variable: 1 if the minute is extra time (90+), otherwise 0\n",
    "    df['goal_et'] = df['goal_minute'].apply(lambda x: 1 if x >= 90 else 0)\n",
    "\n",
    "    # Update goal_minute by adding goal_minute_et to it\n",
    "    df['goal_minute'] = df['goal_minute'] + df['goal_minute_et']\n",
    "\n",
    "    # Clean and format other columns, handling commas in 'stadium_attendance'\n",
    "    df['stadium_attendance'] = df['stadium_attendance'].str.replace(r'[^\\d]', '', regex=True).replace(',', '').astype(int)\n",
    "\n",
    "    # Extract date details\n",
    "    df['short_date'] = df['date'].str.extract(r'\\((.*?)\\)')\n",
    "    df['long_date'] = df['date'].str.split('(').str[0].str.strip()\n",
    "\n",
    "    # Dropping the original 'date' column\n",
    "    df = df.drop(columns=['date'])\n",
    "\n",
    "    return df\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
